{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data_train.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('data_test.csv',  encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_w_sent = pd.read_csv('data_test_with_sentiment.csv',  encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling \n",
    "##### Because the data is not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = data_train.loc[data_train['reviews.sentiment'] == 'negative'].sample(n=1942, random_state=1234)\n",
    "train_sample_positive = data_train.loc[data_train['reviews.sentiment'] == 'positive'].sample(n=1942, random_state=1234)\n",
    "train_sample = train_sample.append(train_sample_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentences = []\n",
    "for i,words in enumerate(train_sample['reviews.text']):\n",
    "    filtered = [word for word in words.split() if word not in stop_words]\n",
    "    filtered_sentences.append(' '.join(filtered))\n",
    "\n",
    "# add new column to store the sentences which stopwords has been removed\n",
    "train_sample['filtered.reviews'] = pd.Series(filtered_sentences, index=train_sample.index)\n",
    "\n",
    "#save filtered sentence data to csv\n",
    "train_sample.to_csv('filtered_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentences_test = []\n",
    "for i,words in enumerate(data_test['reviews.text']):\n",
    "    filtered = [word for word in words.split() if word not in stop_words]\n",
    "    filtered_sentences_test.append(' '.join(filtered))\n",
    "\n",
    "# add new column to store the sentences which stopwords has been removed\n",
    "data_test['filtered.reviews'] = pd.Series(filtered_sentences_test, index=data_test.index)\n",
    "\n",
    "#save filtered sentence data to csv\n",
    "data_test.to_csv('filtered_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentences_test_sent = []\n",
    "for i,words in enumerate(data_test_w_sent['reviews.text']):\n",
    "    filtered = [word for word in words.split() if word not in stop_words]\n",
    "    filtered_sentences_test_sent.append(' '.join(filtered))\n",
    "\n",
    "# add new column to store the sentences which stopwords has been removed\n",
    "data_test_w_sent['filtered.reviews'] = pd.Series(filtered_sentences_test_sent, index=data_test_w_sent.index)\n",
    "\n",
    "#save filtered sentence data to csv\n",
    "data_test_w_sent.to_csv('filtered_test_sent.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Remove punctuation + lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train = train_sample['filtered.reviews']\n",
    "clean = []\n",
    "for i in filtered_train:\n",
    "    clean_str = re.sub(r'[^\\w\\s]',' ', i) #punctual removal\n",
    "    clean_str = re.sub('\\s+', ' ', clean_str) #remove extra space\n",
    "    words = word_tokenize(clean_str)\n",
    "    for w in range(len(words)):\n",
    "        words[w] = lem.lemmatize(words[w])\n",
    "    sentence = \" \".join(words)\n",
    "\n",
    "    clean.append(sentence)\n",
    "train_sample['lemma'] = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_test = data_test['filtered.reviews']\n",
    "clean_test = []\n",
    "for i in filtered_test:\n",
    "    clean_str = re.sub(r'[^\\w\\s]',' ', i) #punctual removal\n",
    "    clean_str = re.sub('\\s+', ' ', clean_str) #remove extra space\n",
    "    words = word_tokenize(clean_str)\n",
    "    for w in range(len(words)):\n",
    "        words[w] = lem.lemmatize(words[w])\n",
    "    sentence = \" \".join(words)\n",
    "\n",
    "    clean_test.append(sentence)\n",
    "data_test['lemma'] = clean_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_test_sent = data_test_w_sent['filtered.reviews']\n",
    "clean_test = []\n",
    "for i in filtered_test_sent:\n",
    "    clean_str = re.sub(r'[^\\w\\s]',' ', i) #punctual removal\n",
    "    clean_str = re.sub('\\s+', ' ', clean_str) #remove extra space\n",
    "    words = word_tokenize(clean_str)\n",
    "    for w in range(len(words)):\n",
    "        words[w] = lem.lemmatize(words[w])\n",
    "    sentence = \" \".join(words)\n",
    "\n",
    "    clean_test.append(sentence)\n",
    "data_test_w_sent['lemma'] = clean_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snowball stemmer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_train = []\n",
    "for words in train_Sample['filtered.reviews']:\n",
    "    #store each words that have been stemmed in an array of stems\n",
    "    stems = []\n",
    "    for word in words.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    #store each sentences from stems in an array of stemmed_train\n",
    "    stemmed_train.append(' '.join(stems))\n",
    "\n",
    "data_train['stemmed.reviews'] = pd.Series(stemmed_train, index=data_train.index)\n",
    "#train_sample.to_csv('stem_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_test = []\n",
    "for words in data_test['filtered_reviews']:\n",
    "    #store each words that have been stemmed in an array of stems\n",
    "    stems = []\n",
    "    for word in words.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    #store each sentences from stems in an array of stemmed_train\n",
    "    stemmed_test.append(' '.join(stems))\n",
    "data_test['stemmed_reviews'] = pd.Series(stemmed_test, index=data_test.index)\n",
    "#data_test.to_csv('stem_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_test_sent = []\n",
    "for words in data_test_w_sent['filtered_reviews']:\n",
    "    #store each words that have been stemmed in an array of stems\n",
    "    stems = []\n",
    "    for word in words.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    #store each sentences from stems in an array of stemmed_train\n",
    "    stemmed_test_sent.append(' '.join(stems))\n",
    "data_test_w_sent['stemmed_reviews'] = pd.Series(stemmed_test_sent, index=data_test_w_sent.index)\n",
    "#data_test_w_sent.to_csv('stem_test_w_sent.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "X = vectorizer.fit_transform(train_sample['reviews.text'])\n",
    "X_test = vectorizer.transform(data_test_w_sent['reviews.text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='word', ngram_range=(1,1))\n",
    "cv.fit(train_sample['reviews.text'])\n",
    "X_cv = cv.transform(train_sample['reviews.text'])\n",
    "X_test_cv = cv.fit_transform(data_test_w_sent['reviews.text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "##### Training data is splitted into train & test data for validation before we test the model with the real testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_sample['reviews.sentiment']\n",
    "test_y = data_test_w_sent['reviews.sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.30\n",
    "seed = 1234 #generate same sample\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_cv, train_y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy training :0.8719646799116998\n",
      "Accuracy testing :0.8018867924528302\n",
      "Confusion Matriks Data Training :\n",
      "[[1175  196]\n",
      " [ 152 1195]]\n",
      "Confusion Matriks Data Testing :\n",
      "[[452 119]\n",
      " [112 483]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support, classification_report \n",
    "\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "nb.fit(X_train, Y_train)\n",
    "\n",
    "pred_y_train = nb.predict(X_train)\n",
    "pred_y_test = nb.predict(X_validation)\n",
    "\n",
    "accuracy_train = accuracy_score(Y_train, pred_y_train)\n",
    "accuracy_test = accuracy_score(Y_validation, pred_y_test)\n",
    "print(\"Accuracy training :\" + str(accuracy_train))\n",
    "print(\"Accuracy testing :\" + str(accuracy_test))\n",
    "print(\"Confusion Matriks Data Training :\\n\" + str(sklearn.metrics.confusion_matrix(Y_train, pred_y_train)))\n",
    "print(\"Confusion Matriks Data Testing :\\n\" + str(sklearn.metrics.confusion_matrix(Y_validation, pred_y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Data Training : 0.9521707137601177\n",
      "Akurasi Data Testing : 0.7770154373927959\n",
      "Confusion Matriks Data Training :\n",
      "[[1291   80]\n",
      " [  50 1297]]\n",
      "Confusion Matriks Data Testing :\n",
      "[[443 128]\n",
      " [132 463]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "y_val_pred = logreg.predict(X_validation)\n",
    "print(\"Akurasi Data Training : \" + str(logreg.score(X_train, Y_train)))\n",
    "print(\"Akurasi Data Testing : \" + str(logreg.score(X_validation, Y_validation)))\n",
    "print(\"Confusion Matriks Data Training :\\n\" + str(sklearn.metrics.confusion_matrix(Y_train, y_train_pred)))\n",
    "print(\"Confusion Matriks Data Testing :\\n\" + str(sklearn.metrics.confusion_matrix(Y_validation, y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomforest = RandomForestClassifier(random_state=seed)\n",
    "randomforest.fit(X_train, Y_train)\n",
    "\n",
    "pred_y_train = randomforest.predict(X_train)\n",
    "pred_y_test = randomforest.predict(X_validation)\n",
    "\n",
    "accuracy_train = accuracy_score(Y_train, pred_y_train)\n",
    "accuracy_test = accuracy_score(Y_validation, pred_y_test)\n",
    "print(\"Accuracy training :\" + str(accuracy_train))\n",
    "print(\"Accuracy testing :\" + str(accuracy_test))\n",
    "print(\"Confusion Matriks Data Training :\\n\" + str(sklearn.metrics.confusion_matrix(Y_train, y_train_pred)))\n",
    "print(\"Confusion Matriks Data Testing :\\n\" + str(sklearn.metrics.confusion_matrix(Y_validation, y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "pred_y_train = dt.predict(X_train)\n",
    "pred_y_test = dt.predict(X_validation)\n",
    "\n",
    "accuracy_train = accuracy_score(Y_train, pred_y_train)\n",
    "accuracy_test = accuracy_score(Y_validation, pred_y_test)\n",
    "print(\"Accuracy training :\" + str(accuracy_train))\n",
    "print(\"Accuracy testing :\" + str(accuracy_test))\n",
    "print(\"Confusion Matriks Data Training :\\n\" + str(sklearn.metrics.confusion_matrix(Y_train, y_train_pred)))\n",
    "print(\"Confusion Matriks Data Testing :\\n\" + str(sklearn.metrics.confusion_matrix(Y_validation, y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy training :0.9738778513612951\n",
      "Accuracy testing :0.7392795883361921\n",
      "Confusion Matriks Data Training :\n",
      "[[1291   80]\n",
      " [  50 1297]]\n",
      "Confusion Matriks Data Testing :\n",
      "[[443 128]\n",
      " [132 463]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel=\"linear\")\n",
    "svc.fit(X_train, Y_train)\n",
    "pred_y_train = svc.predict(X_train)\n",
    "pred_y_test = svc.predict(X_validation)\n",
    "\n",
    "accuracy_train = accuracy_score(Y_train, pred_y_train)\n",
    "accuracy_test = accuracy_score(Y_validation, pred_y_test)\n",
    "print(\"Accuracy training :\" + str(accuracy_train))\n",
    "print(\"Accuracy testing :\" + str(accuracy_test))\n",
    "print(\"Confusion Matriks Data Training :\\n\" + str(sklearn.metrics.confusion_matrix(Y_train, y_train_pred)))\n",
    "print(\"Confusion Matriks Data Testing :\\n\" + str(sklearn.metrics.confusion_matrix(Y_validation, y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Radial Basis Function (RBF) Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_rbf = SVC()\n",
    "svc_rbf.fit(X_train, Y_train)\n",
    "pred_y_train = svc_rbf.predict(X_train)\n",
    "pred_y_test = svc_rbf.predict(X_validation)\n",
    "\n",
    "accuracy_train = accuracy_score(Y_train, pred_y_train)\n",
    "accuracy_test = accuracy_score(Y_validation, pred_y_test)\n",
    "print(\"Accuracy training :\" + str(accuracy_train))\n",
    "print(\"Accuracy testing :\" + str(accuracy_test))\n",
    "print(\"Confusion Matriks Data Training :\\n\" + str(sklearn.metrics.confusion_matrix(Y_train, y_train_pred)))\n",
    "print(\"Confusion Matriks Data Testing :\\n\" + str(sklearn.metrics.confusion_matrix(Y_validation, y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_poly = SVC(kernel='poly')\n",
    "svc_poly.fit(X_train, Y_train)\n",
    "pred_y_train = svc_poly.predict(X_train)\n",
    "pred_y_test = svc_poly.predict(X_validation)\n",
    "\n",
    "accuracy_train = accuracy_score(Y_train, pred_y_train)\n",
    "accuracy_test = accuracy_score(Y_validation, pred_y_test)\n",
    "print(\"Accuracy training :\" + str(accuracy_train))\n",
    "print(\"Accuracy testing :\" + str(accuracy_test))\n",
    "print(\"Confusion Matriks Data Training :\\n\" + str(sklearn.metrics.confusion_matrix(Y_train, y_train_pred)))\n",
    "print(\"Confusion Matriks Data Testing :\\n\" + str(sklearn.metrics.confusion_matrix(Y_validation, y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_sig = SVC(kernel='sigmoid')\n",
    "svc_sig.fit(X_train, Y_train)\n",
    "pred_y_train = svc_sig.predict(X_train)\n",
    "pred_y_test = svc_sig.predict(X_validation)\n",
    "\n",
    "accuracy_train = accuracy_score(Y_train, pred_y_train)\n",
    "accuracy_test = accuracy_score(Y_validation, pred_y_test)\n",
    "print(\"Accuracy training :\" + str(accuracy_train))\n",
    "print(\"Accuracy testing :\" + str(accuracy_test))\n",
    "print(\"Confusion Matriks Data Training :\\n\" + str(sklearn.metrics.confusion_matrix(Y_train, y_train_pred)))\n",
    "print(\"Confusion Matriks Data Testing :\\n\" + str(sklearn.metrics.confusion_matrix(Y_validation, y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with real data (data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = pickle.dumps(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 8411 should be equal to 5834, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-e03e1ed5ef2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifier_from_pickle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Use the loaded pickled model to make predictions of data_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier_from_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier_from_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\series 9\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \"\"\"\n\u001b[1;32m--> 548\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\series 9\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \"\"\"\n\u001b[1;32m--> 308\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\series 9\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    457\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0;32m    458\u001b[0m                              \u001b[1;34m\"the number of features at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[0;32m    460\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X.shape[1] = 8411 should be equal to 5834, the number of features at training time"
     ]
    }
   ],
   "source": [
    "# Load the pickled model\n",
    "classifier_from_pickle = pickle.loads(saved_model)\n",
    "# Use the loaded pickled model to make predictions of data_test\n",
    "x_test_pred = classifier_from_pickle.predict(X_test_cv)\n",
    "#accuracy\n",
    "result = classifier_from_pickle.score(X_test_cv, test_y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "positif = train_sample[\"filtered.reviews\"][train_sample[\"reviews.sentiment\"]=='positive'] \n",
    "negatif = train_sample[\"filtered.reviews\"][train_sample[\"reviews.sentiment\"]=='negative'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud \n",
    "import matplotlib.pyplot as plt \n",
    "wordcloud = WordCloud(random_state=seed).generate(\" \".join(positif)) \n",
    "plt.figure(figsize = (15,7)) \n",
    "plt.imshow(wordcloud,interpolation = 'bilinear') \n",
    "plt.axis(\"off\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud \n",
    "import matplotlib.pyplot as plt \n",
    "wordcloud = WordCloud(random_state=seed).generate(\" \".join(negatif)) \n",
    "plt.figure(figsize = (15,7)) \n",
    "plt.imshow(wordcloud,interpolation = 'bilinear') \n",
    "plt.axis(\"off\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization + Remove Punctuation + Without Removing Stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ps = PorterStemmer()\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered = train_sample['reviews.text']\n",
    "clean = []\n",
    "for i in filtered:\n",
    "    clean_str = re.sub(r'[^\\w\\s]',' ', i) #punctual removal\n",
    "    clean_str = re.sub('\\s+', ' ', clean_str) #remove extra space\n",
    "    words = word_tokenize(clean_str)\n",
    "    for w in range(len(words)):\n",
    "        #print(ps.stem(words[w]))\n",
    "        words[w] = lem.lemmatize(words[w])\n",
    "    sentence = \" \".join(words)\n",
    "\n",
    "    clean.append(sentence)\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample['stemmed'] = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = train_sample[\"stemmed\"][train_sample[\"reviews.sentiment\"]=='positive'] \n",
    "negative = train_sample[\"stemmed\"][train_sample[\"reviews.sentiment\"]=='negative'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud \n",
    "import matplotlib.pyplot as plt \n",
    "wordcloud = WordCloud(random_state=21).generate(\" \".join(positive)) \n",
    "plt.figure(figsize = (15,7)) \n",
    "plt.imshow(wordcloud,interpolation = 'bilinear') \n",
    "plt.axis(\"off\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud \n",
    "import matplotlib.pyplot as plt \n",
    "wordcloud = WordCloud(random_state=21).generate(\" \".join(negative)) \n",
    "plt.figure(figsize = (15,7)) \n",
    "plt.imshow(wordcloud,interpolation = 'bilinear') \n",
    "plt.axis(\"off\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_test_w_sent.sample(n=3884, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_sample['stemmed']\n",
    "train_y = train_sample['reviews.sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer='word', ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vect.fit(train_x) \n",
    "train_x_feat = count_vect.transform(train_x)\n",
    "train_x_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test['filtered_reviews']\n",
    "test_y = test['reviews.sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect.fit(test_x) \n",
    "test_x_feat = count_vect.fit_transform(test_x) \n",
    "test_x_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support, classification_report \n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel=\"linear\")\n",
    "svc.fit(train_x_feat, train_y)\n",
    "pred_y_train = svc.predict(train_x_feat)\n",
    "pred_y_test = svc.predict(test_x_feat)\n",
    "\n",
    "accuracy_train = accuracy_score(train_y, pred_y_train)\n",
    "accuracy_test = accuracy_score(test_y, pred_y_test) \n",
    "print(\"Accuracy training :\" + str(accuracy_train)) \n",
    "print(\"Accuracy testing :\" + str(accuracy_test))\n",
    "cnf_matrix = confusion_matrix(test_y, pred_y_test)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support, classification_report \n",
    "classifier = naive_bayes.MultinomialNB()\n",
    "classifier.fit(train_x_feat, train_y)\n",
    "\n",
    "pred_y_train = classifier.predict(train_x_feat)\n",
    "pred_y_test = classifier.predict(test_x_feat)\n",
    "\n",
    "#print(pred_y[0:30]) \n",
    "#print(test_y[0:30]) \n",
    "accuracy_train = accuracy_score(train_y, pred_y_train)\n",
    "accuracy_test = accuracy_score(test_y, pred_y_test) \n",
    "print(\"Accuracy training :\" + str(accuracy_train)) \n",
    "print(\"Accuracy testing :\" + str(accuracy_test))\n",
    "cnf_matrix = confusion_matrix(test_y, pred_y_test)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization + Remove Stopwords + Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = train_sample['filtered_reviews']\n",
    "clean = []\n",
    "for i in filtered:\n",
    "    clean_str = re.sub(r'[^\\w\\s]',' ', i) #punctual removal\n",
    "    clean_str = re.sub('\\s+', ' ', clean_str) #remove extra space\n",
    "    words = word_tokenize(clean_str)\n",
    "    for w in range(len(words)):\n",
    "        words[w] = lem.lemmatize(words[w])\n",
    "    sentence = \" \".join(words)\n",
    "\n",
    "    clean.append(sentence)\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample['stemmed'] = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = train_sample[\"stemmed\"][train_sample[\"reviews.sentiment\"]=='positive'] \n",
    "negative = train_sample[\"stemmed\"][train_sample[\"reviews.sentiment\"]=='negative'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud \n",
    "import matplotlib.pyplot as plt \n",
    "wordcloud = WordCloud(random_state=21).generate(\" \".join(positive)) \n",
    "plt.figure(figsize = (15,7)) \n",
    "plt.imshow(wordcloud,interpolation = 'bilinear') \n",
    "plt.axis(\"off\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud \n",
    "import matplotlib.pyplot as plt \n",
    "wordcloud = WordCloud(random_state=21).generate(\" \".join(negative)) \n",
    "plt.figure(figsize = (15,7)) \n",
    "plt.imshow(wordcloud,interpolation = 'bilinear') \n",
    "plt.axis(\"off\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
